{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0609d183",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6870e",
   "metadata": {},
   "source": [
    "Loading trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d05eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35648afd",
   "metadata": {},
   "source": [
    "Clean Duplicated Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7112e0",
   "metadata": {},
   "source": [
    "Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trainset.drop(columns='ClassLabel')\n",
    "y = trainset['ClassLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val = train_test_split(x,y,test_size = 0.2, stratify = y,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39e384",
   "metadata": {},
   "source": [
    "Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82716e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6a5c9",
   "metadata": {},
   "source": [
    "Columns type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a676b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_col = \"URL\"\n",
    "robust_cols = [\"url_length\", \"url_entropy\", \"token_count\", \"path_length\", \"number_of_digits\"]\n",
    "standard_cols = [\"dot_count\", \"subdomain_count\", \"query_param_count\", \"domain_name_length\", \"percentage_numeric_chars\"]\n",
    "minmax_cols = [\"tld_length\"]\n",
    "binary_cols = [\"has_ip_address\", \"https_flag\", \"has_hyphen_in_domain\", \"tld_popularity\", \"suspicious_file_extension\"]\n",
    "numeric_cols = robust_cols + standard_cols + minmax_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6fa89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ac43738",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer(\"all-mpnet-base-v2\", device=device)\n",
    "def encode_urls(urls):\n",
    "    embeddings = sbert_model.encode(urls, batch_size=256, show_progress_bar=True)\n",
    "    return embeddings.astype(np.float16)\n",
    "\n",
    "train_urls = x_train[text_col].tolist()\n",
    "url_embeddings = encode_urls(train_urls)\n",
    "embedding_cols = [f\"url_emb_{i}\" for i in range(url_embeddings.shape[1])]\n",
    "df_train_embeddings = pd.DataFrame(url_embeddings, columns=embedding_cols, index=x_train.index)\n",
    "\n",
    "val_urls = x_val[text_col].tolist()\n",
    "val_embeddings = encode_urls(val_urls)\n",
    "df_val_embeddings = pd.DataFrame(val_embeddings, columns=embedding_cols, index=x_val.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full = pd.concat([df_train_embeddings, x_train[numeric_cols + binary_cols]], axis=1)\n",
    "x_val_full = pd.concat([df_val_embeddings, x_val[numeric_cols + binary_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e58236",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"robust\", RobustScaler(), robust_cols),\n",
    "        (\"standard\", StandardScaler(), standard_cols),\n",
    "        (\"minmax\", MinMaxScaler(), minmax_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c182835",
   "metadata": {},
   "source": [
    "XGBOOST and MLP Parameters for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c7e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline = Pipeline([\n",
    "    (\"scaler\", preprocessor),\n",
    "    (\"xgb\", XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.015,\n",
    "        max_depth=7,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.0,\n",
    "        reg_lambda=0.1,\n",
    "        eval_metric=\"logloss\",\n",
    "        use_label_encoder=False,\n",
    "        tree_method=\"gpu_hist\",  # GPU\n",
    "        gpu_id=0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "mlp_pipeline = Pipeline([\n",
    "    (\"scaler\", preprocessor),\n",
    "    (\"pca\", PCA(n_components=128, random_state=42)),\n",
    "    (\"mlp\", MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        max_iter=500,\n",
    "        alpha=0.001,\n",
    "        solver='adam',\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=20,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1d157",
   "metadata": {},
   "source": [
    "Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dae9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"xgboost\", xgb_pipeline),\n",
    "        (\"mlp_base\", mlp_pipeline)\n",
    "    ],\n",
    "    final_estimator=MLPClassifier(\n",
    "        hidden_layer_sizes=(64, 32),\n",
    "        max_iter=500,\n",
    "        solver='adam',\n",
    "        alpha=0.001,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=20,\n",
    "        random_state=42\n",
    "    ),\n",
    "    stack_method=\"predict_proba\",\n",
    "    n_jobs=-1,\n",
    "    passthrough=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79657c69",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'xgboost__xgb__n_estimators': [300, 400, 500],\n",
    "    'xgboost__xgb__max_depth': [5, 7, 9],\n",
    "    'xgboost__xgb__learning_rate': [0.01, 0.015, 0.02],\n",
    "    'xgboost__xgb__subsample': [0.7, 0.8, 0.9],\n",
    "    'xgboost__xgb__colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'xgboost__xgb__reg_alpha': [0.0, 0.1, 0.5],\n",
    "    'mlp_base__mlp__hidden_layer_sizes': [(128,64), (256,128,64), (512,256,128)],\n",
    "    'final_estimator__hidden_layer_sizes': [(64,32), (128,64)]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=stack_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=15,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8df96",
   "metadata": {},
   "source": [
    "Fitting and review AUROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d3630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting GPU-ready Stacking Model with extended hyperparameter tuning...\")\n",
    "random_search.fit(x_train_full, y_train)\n",
    "\n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "y_pred_proba = random_search.predict_proba(x_val_full)[:,1]\n",
    "auroc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f\" FINAL AUROC on validation set: {auroc:.5f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a66ce8",
   "metadata": {},
   "source": [
    "Predict test set and save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e603ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv(\"test.csv\")\n",
    "test_urls = testset[text_col].tolist()\n",
    "test_embeddings = encode_urls(test_urls)\n",
    "df_test_embeddings = pd.DataFrame(test_embeddings, columns=embedding_cols, index=testset.index)\n",
    "\n",
    "for col in binary_cols:\n",
    "    if col not in testset.columns:\n",
    "        testset[col] = 0\n",
    "\n",
    "x_test_full = pd.concat([df_test_embeddings, testset[numeric_cols + binary_cols]], axis=1)\n",
    "x_test_full = x_test_full.reindex(columns=x_train_full.columns, fill_value=0)\n",
    "\n",
    "probs = random_search.predict_proba(x_test_full)[:,1]\n",
    "class_labels = (probs >= 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": testset.get(\"ID\", np.arange(1,len(probs)+1)),\n",
    "    \"class_label\": class_labels\n",
    "})\n",
    "\n",
    "submission.to_csv(\"Final Result.csv\", index=False)\n",
    "print(\"Submission saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
